@article{issan_predicting_2023,
	title = {Predicting solar wind streams from the inner-heliosphere to {Earth} via shifted operator inference},
	volume = {473},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999122007525},
	doi = {10.1016/j.jcp.2022.111689},
	language = {en},
	urldate = {2024-04-08},
	journal = {Journal of Computational Physics},
	author = {Issan, Opal and Kramer, Boris},
	year = {2023},
	pages = {111689},
}

@article{sharma_hamiltonian_2022,
	title = {Hamiltonian operator inference: {Physics}-preserving learning of reduced-order models for canonical {Hamiltonian} systems},
	volume = {431},
	issn = {01672789},
	shorttitle = {Hamiltonian operator inference},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167278921002682},
	doi = {10.1016/j.physd.2021.133122},
	language = {en},
	urldate = {2024-04-08},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Sharma, Harsh and Wang, Zhu and Kramer, Boris},
	year = {2022},
	pages = {133122},
}

@article{ruthotto_deep_2020,
	title = {Deep {Neural} {Networks} {Motivated} by {Partial} {Differential} {Equations}},
	volume = {62},
	issn = {0924-9907, 1573-7683},
	url = {http://link.springer.com/10.1007/s10851-019-00903-1},
	doi = {10.1007/s10851-019-00903-1},
	language = {en},
	number = {3},
	urldate = {2024-04-08},
	journal = {Journal of Mathematical Imaging and Vision},
	author = {Ruthotto, Lars and Haber, Eldad},
	year = {2020},
	pages = {352--364},
}

@article{you_learning_2022,
	title = {Learning {Deep} {Implicit} {Fourier} {Neural} {Operators} ({IFNOs}) with {Applications} to {Heterogeneous} {Material} {Modeling}},
	volume = {398},
	issn = {00457825},
	url = {http://arxiv.org/abs/2203.08205},
	doi = {10.1016/j.cma.2022.115296},
	urldate = {2024-04-08},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {You, Huaiqian and Zhang, Quinn and Ross, Colton J. and Lee, Chung-Hao and Yu, Yue},
	year = {2022},
	note = {arXiv:2203.08205 [cond-mat]},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Materials Science},
	pages = {115296},
}

@misc{liu-schiaffini_neural_2024,
	title = {Neural {Operators} with {Localized} {Integral} and {Differential} {Kernels}},
	url = {http://arxiv.org/abs/2402.16845},
	doi = {10.48550/arXiv.2402.16845},
	urldate = {2024-04-08},
	publisher = {arXiv},
	author = {Liu-Schiaffini, Miguel and Berner, Julius and Bonev, Boris and Kurth, Thorsten and Azizzadenesheli, Kamyar and Anandkumar, Anima},
	year = {2024},
	note = {arXiv:2402.16845 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Mathematics - Numerical Analysis},
}

@misc{massaroli_dissecting_2021,
	title = {Dissecting {Neural} {ODEs}},
	url = {http://arxiv.org/abs/2002.08071},
	doi = {10.48550/arXiv.2002.08071},
	urldate = {2024-04-08},
	publisher = {arXiv},
	author = {Massaroli, Stefano and Poli, Michael and Park, Jinkyoo and Yamashita, Atsushi and Asama, Hajime},
	year = {2021},
	note = {arXiv:2002.08071 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{perona_scale-space_1990,
	title = {Scale-space and edge detection using anisotropic diffusion},
	volume = {12},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/document/56205},
	doi = {10.1109/34.56205},
	number = {7},
	urldate = {2024-04-09},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Perona, P. and Malik, J.},
	year = {1990},
	keywords = {Image edge detection, Anisotropic magnetoresistance, Smoothing methods, Diffusion processes, Detectors, Hardware},
	pages = {629--639},
}

@misc{greydanus_hamiltonian_2019,
	title = {Hamiltonian {Neural} {Networks}},
	url = {http://arxiv.org/abs/1906.01563},
	doi = {10.48550/arXiv.1906.01563},
	urldate = {2024-04-08},
	publisher = {arXiv},
	author = {Greydanus, Sam and Dzamba, Misko and Yosinski, Jason},
	year = {2019},
	note = {arXiv:1906.01563 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing},
}

@misc{haber_learning_2017,
	title = {Learning across scales - {A} multiscale method for {Convolution} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1703.02009},
	doi = {10.48550/arXiv.1703.02009},
	urldate = {2024-04-09},
	publisher = {arXiv},
	author = {Haber, Eldad and Ruthotto, Lars and Holtham, Elliot and Jun, Seong-Hwan},
	year = {2017},
	note = {arXiv:1703.02009 [cs]},
	keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Computer Vision and Pattern Recognition},
}

@misc{huh_time-reversal_2020,
	title = {Time-{Reversal} {Symmetric} {ODE} {Network}},
	url = {https://arxiv.org/abs/2007.11362v3},
	abstract = {Time-reversal symmetry, which requires that the dynamics of a system should not change with the reversal of time axis, is a fundamental property that frequently holds in classical and quantum mechanics. In this paper, we propose a novel loss function that measures how well our ordinary differential equation (ODE) networks comply with this time-reversal symmetry; it is formally defined by the discrepancy in the time evolutions of ODE networks between forward and backward dynamics. Then, we design a new framework, which we name as Time-Reversal Symmetric ODE Networks (TRS-ODENs), that can learn the dynamics of physical systems more sample-efficiently by learning with the proposed loss function. We evaluate TRS-ODENs on several classical dynamics, and find they can learn the desired time evolution from observed noisy and complex trajectories. We also show that, even for systems that do not possess the full time-reversal symmetry, TRS-ODENs can achieve better predictive performances over baselines.},
	language = {en},
	urldate = {2024-04-09},
	journal = {arXiv.org},
	author = {Huh, In and Yang, Eunho and Hwang, Sung Ju and Shin, Jinwoo},
	month = jul,
	year = {2020},
}