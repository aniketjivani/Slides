@article{gorodetsky_generalized_2020,
	title = {A generalized approximate control variate framework for multifidelity uncertainty quantification},
	volume = {408},
	issn = {0021-9991},
	url = {https://www.sciencedirect.com/science/article/pii/S0021999120300310},
	doi = {https://doi.org/10.1016/j.jcp.2020.109257},
	abstract = {We describe and analyze a variance reduction approach for Monte Carlo (MC) sampling that accelerates the estimation of statistics of computationally expensive simulation models using an ensemble of models with lower cost. These lower cost models — which are typically lower fidelity with unknown statistics — are used to reduce the variance in statistical estimators relative to a MC estimator with equivalent cost. We derive the conditions under which our proposed approximate control variate framework recovers existing multifidelity variance reduction schemes as special cases. We demonstrate that existing recursive/nested strategies are suboptimal because they use the additional low-fidelity models only to efficiently estimate the unknown mean of the first low-fidelity model. As a result, they cannot achieve variance reduction beyond that of a control variate estimator that uses a single low-fidelity model with known mean. However, there often exists about an order-of-magnitude gap between the maximum achievable variance reduction using all low-fidelity models and that achieved by a single low-fidelity model with known mean. We show that our proposed approach can exploit this gap to achieve greater variance reduction by using non-recursive sampling schemes. The proposed strategy reduces the total cost of accurately estimating statistics, especially in cases where only low-fidelity simulation models are accessible for additional evaluations. Several analytic examples and an example with a hyperbolic PDE describing elastic wave propagation in heterogeneous media are used to illustrate the main features of the methodology.},
	journal = {Journal of Computational Physics},
	author = {Gorodetsky, Alex A. and Geraci, Gianluca and Eldred, Michael S. and Jakeman, John D.},
	year = {2020},
	keywords = {Control variates, Monte Carlo, Multifidelity modeling, Variance reduction},
	pages = {109257},
}

@article{bomarito_optimization_2022,
	title = {On the optimization of approximate control variates with parametrically defined estimators},
	volume = {451},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999121007774},
	doi = {10.1016/j.jcp.2021.110882},
	language = {en},
	urldate = {2022-05-16},
	journal = {Journal of Computational Physics},
	author = {Bomarito, G.F. and Leser, P.E. and Warner, J.E. and Leser, W.P.},
	month = feb,
	year = {2022},
	pages = {110882},
	annote = {Adds optimization of parameters in ACV-KL estimator from Gorodetsky
},
	file = {Submitted Version:/Users/me-tcoons/Zotero/storage/NGQ7FE2E/Bomarito et al. - 2022 - On the optimization of approximate control variate.pdf:application/pdf},
}

@article{peherstorfer_optimal_2016,
	title = {Optimal {Model} {Management} for {Multifidelity} {Monte} {Carlo} {Estimation}},
	volume = {38},
	issn = {1064-8275, 1095-7197},
	url = {http://epubs.siam.org/doi/10.1137/15M1046472},
	doi = {10.1137/15M1046472},
	language = {en},
	number = {5},
	urldate = {2022-09-15},
	journal = {SIAM Journal on Scientific Computing},
	author = {Peherstorfer, Benjamin and Willcox, Karen and Gunzburger, Max},
	month = jan,
	year = {2016},
	pages = {A3163--A3194},
	file = {Full Text:/Users/me-tcoons/Zotero/storage/KWMLVXZV/Peherstorfer et al. - 2016 - Optimal Model Management for Multifidelity Monte C.pdf:application/pdf},
}

@article{schaden_multilevel_2020,
	title = {On {Multilevel} {Best} {Linear} {Unbiased} {Estimators}},
	volume = {8},
	issn = {2166-2525},
	url = {https://epubs.siam.org/doi/10.1137/19M1263534},
	doi = {10.1137/19M1263534},
	language = {en},
	number = {2},
	urldate = {2024-02-11},
	journal = {SIAM/ASA Journal on Uncertainty Quantification},
	author = {Schaden, Daniel and Ullmann, Elisabeth},
	month = jan,
	year = {2020},
	pages = {601--635},
}

@article{xu_bandit-learning_2022,
	title = {A {Bandit}-{Learning} {Approach} to {Multifidelity} {Approximation}},
	volume = {44},
	issn = {1064-8275, 1095-7197},
	url = {https://epubs.siam.org/doi/10.1137/21M1408312},
	doi = {10.1137/21M1408312},
	language = {en},
	number = {1},
	urldate = {2023-07-08},
	journal = {SIAM Journal on Scientific Computing},
	author = {Xu, Yiming and Keshavarzzadeh, Vahid and Kirby, Robert M. and Narayan, Akil},
	month = feb,
	year = {2022},
	pages = {A150--A175},
	file = {Submitted Version:/Users/me-tcoons/Zotero/storage/DYAWGKVU/Xu et al. - 2022 - A Bandit-Learning Approach to Multifidelity Approx.pdf:application/pdf},
}
@article{pham_ensemble_2022,
	title = {Ensemble {Approximate} {Control} {Variate} {Estimators}: {Applications} to {MultiFidelity} {Importance} {Sampling}},
	volume = {10},
	issn = {2166-2525},
	shorttitle = {Ensemble {Approximate} {Control} {Variate} {Estimators}},
	url = {https://epubs.siam.org/doi/10.1137/21M1390426},
	doi = {10.1137/21M1390426},
	language = {en},
	number = {3},
	urldate = {2023-07-08},
	journal = {SIAM/ASA Journal on Uncertainty Quantification},
	author = {Pham, Trung and Gorodetsky, Alex A.},
	month = sep,
	year = {2022},
	pages = {1250--1292},
	file = {Submitted Version:/Users/me-tcoons/Zotero/storage/HD6SGN5G/Pham and Gorodetsky - 2022 - Ensemble Approximate Control Variate Estimators A.pdf:application/pdf},
}

@article{Kidd2022,
	author = {Brian Kidd and Matthias Katzfuss},
	title = {{Bayesian Nonstationary and Nonparametric Covariance Estimation for Large Spatial Data (with Discussion)}},
	volume = {17},
	journal = {Bayesian Analysis},
	number = {1},
	publisher = {International Society for Bayesian Analysis},
	pages = {291 -- 351},
	keywords = {Bayesian linear regression, climate-model emulation, modified Cholesky factorization, ordered conditional independence, Sparsity, Vecchia approximation},
	year = {2022},
	doi = {10.1214/21-BA1273},
	URL = {https://doi.org/10.1214/21-BA1273}
}

@article{archakov2020,
	ISSN = {00129682, 14680262},
	URL = {https://www.jstor.org/stable/48628873},
	abstract = {We introduce a novel parametrization of the correlation matrix. The reparametrization facilitates modeling of correlation and covariance matrices by an unrestricted vector, where positive definiteness is an innate property. This parametrization can be viewed as a generalization of Fisher’s Z-transformation to higher dimensions and has a wide range of potential applications. An algorithm for reconstructing the unique n × n correlation matrix from any vector in ℝn(n-1)/2 is provided, and we derive its numerical complexity.},
	author = {Ilya Archakov and Peter Reinhard Hansen},
	journal = {Econometrica},
	number = {4},
	pages = {pp. 1699--1715},
	publisher = {[Wiley, The Econometric Society]},
	title = {A NEW PARAMETRIZATION OF CORRELATION MATRICES},
	urldate = {2024-02-13},
	volume = {89},
	year = {2021}
}

@article{liu_comparison_2016,
	title = {Comparison of inverse wishart and separation-strategy priors for bayesian estimation of covariance parameter matrix in growth curve analysis},
	volume = {23},
	issn = {1070-5511, 1532-8007},
	url = {http://www.tandfonline.com/doi/full/10.1080/10705511.2015.1057285},
	doi = {10.1080/10705511.2015.1057285},
	language = {en},
	number = {3},
	urldate = {2024-02-13},
	journal = {Structural Equation Modeling: A Multidisciplinary Journal},
	author = {Liu, Haiyan and Zhang, Zhiyong and Grimm, Kevin J.},
	month = may,
	year = {2016},
	pages = {354--367},
}

@article{berger_bayesian_2020,
	title = {Bayesian analysis of the covariance matrix of a multivariate normal distribution with a new class of priors},
	volume = {48},
	issn = {0090-5364, 2168-8966},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-48/issue-4/Bayesian-analysis-of-the-covariance-matrix-of-a-multivariate-normal/10.1214/19-AOS1891.full},
	doi = {10.1214/19-AOS1891},
	abstract = {Bayesian analysis for the covariance matrix of a multivariate normal distribution has received a lot of attention in the last two decades. In this paper, we propose a new class of priors for the covariance matrix, including both inverse Wishart and reference priors as special cases. The main motivation for the new class is to have available priors—both subjective and objective—that do not “force eigenvalues apart,” which is a criticism of inverse Wishart and Jeffreys priors. Extensive comparison of these “shrinkage priors” with inverse Wishart and Jeffreys priors is undertaken, with the new priors seeming to have considerably better performance. A number of curious facts about the new priors are also observed, such as that the posterior distribution will be proper with just three vector observations from the multivariate normal distribution—regardless of the dimension of the covariance matrix—and that useful inference about features of the covariance matrix can be possible. Finally, a new MCMC algorithm is developed for this class of priors and is shown to be computationally effective for matrices of up to 100 dimensions.},
	number = {4},
	urldate = {2024-02-13},
	journal = {The Annals of Statistics},
	author = {Berger, James O. and Sun, Dongchu and Song, Chengyuan},
	month = aug,
	year = {2020},
	keywords = {62C10, 62F15, 62H10, 62H86, Covariance, inverse Wishart prior, objective priors, shrinkage priors},
	pages = {2381--2403},
}
