@inproceedings{giunta_perspectives_2004,
	address = {Albany, New York},
	title = {Perspectives in {Optimization} {Under} {Uncertainty}: {Algorithms} and {Applications}},
	isbn = {9781624100192},
	shorttitle = {Perspectives in {Optimization} {Under} {Uncertainty}},
	url = {http://arc.aiaa.org/doi/10.2514/6.2004-4451},
	doi = {10.2514/6.2004-4451},
	language = {en},
	urldate = {2024-03-15},
	booktitle = {10th {AIAA}/{ISSMO} {Multidisciplinary} {Analysis} and {Optimization} {Conference}},
	publisher = {American Institute of Aeronautics and Astronautics},
	author = {Giunta, Anthony and Eldred, Michael and Swiler, Laura and Trucano, Timothy and Wojtkiewicz, Steven},
	month = aug,
	year = {2004},
}

@article{hennig_probabilistic_2015,
	title = {Probabilistic numerics and uncertainty in computations},
	volume = {471},
	issn = {1364-5021, 1471-2946},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspa.2015.0142},
	doi = {10.1098/rspa.2015.0142},
	language = {en},
	number = {2179},
	urldate = {2024-03-15},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Hennig, Philipp and Osborne, Michael A. and Girolami, Mark},
	month = jul,
	year = {2015},
	pages = {20150142},
}

@article{Chkrebtii2016,
author = {Oksana A. Chkrebtii and David A. Campbell and Ben Calderhead and Mark A. Girolami},
title = {{Bayesian Solution Uncertainty Quantification for Differential Equations}},
volume = {11},
journal = {Bayesian Analysis},
number = {4},
publisher = {International Society for Bayesian Analysis},
pages = {1239 -- 1267},
keywords = {Bayesian numerical analysis, differential equation models, Gaussian processes, uncertainty in computer models, uncertainty quantification},
year = {2016},
doi = {10.1214/16-BA1017},
URL = {https://doi.org/10.1214/16-BA1017}
}

@article{guo_bayesian_2022,
	title = {Bayesian operator inference for data-driven reduced-order modeling},
	volume = {402},
	issn = {00457825},
	url = {http://arxiv.org/abs/2204.10829},
	doi = {10.1016/j.cma.2022.115336},
	abstract = {This work proposes a Bayesian inference method for the reduced-order modeling of time-dependent systems. Informed by the structure of the governing equations, the task of learning a reduced-order model from data is posed as a Bayesian inverse problem with Gaussian prior and likelihood. The resulting posterior distribution characterizes the operators defining the reduced-order model, hence the predictions subsequently issued by the reduced-order model are endowed with uncertainty. The statistical moments of these predictions are estimated via a Monte Carlo sampling of the posterior distribution. Since the reduced models are fast to solve, this sampling is computationally efficient. Furthermore, the proposed Bayesian framework provides a statistical interpretation of the regularization term that is present in the deterministic operator inference problem, and the empirical Bayes approach of maximum marginal likelihood suggests a selection algorithm for the regularization hyperparameters. The proposed method is demonstrated on two examples: the compressible Euler equations with noise-corrupted observations, and a single-injector combustion process.},
	urldate = {2024-02-29},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Guo, Mengwu and McQuarrie, Shane A. and Willcox, Karen E.},
	month = dec,
	year = {2022},
	note = {arXiv:2204.10829 [cs, math, stat]},
	keywords = {Mathematics - Numerical Analysis, Computer Science - Computational Engineering, Finance, and Science, Statistics - Computation, 62F15, 65M32, 35F20, 35R30, 80A25, J.2},
	pages = {115336},
}

@misc{ye_gaussian_2023,
	title = {Gaussian process learning of nonlinear dynamics},
	url = {http://arxiv.org/abs/2312.12193},
	doi = {10.48550/arXiv.2312.12193},
	abstract = {One of the pivotal tasks in scientific machine learning is to represent underlying dynamical systems from time series data. Many methods for such dynamics learning explicitly require the derivatives of state data, which are not directly available and can be approximated conventionally by finite differences. However, the discrete approximations of time derivatives may result in a poor estimation when state data are scarce and/or corrupted by noise, thus compromising the predictiveness of the learned dynamical models. To overcome this technical hurdle, we propose a new method that learns nonlinear dynamics through a Bayesian inference of characterizing model parameters. This method leverages a Gaussian process representation of states, and constructs a likelihood function using the correlation between state data and their derivatives, yet prevents explicit evaluations of time derivatives. Through a Bayesian scheme, a probabilistic estimate of the model parameters is given by the posterior distribution, and thus a quantification is facilitated for uncertainties from noisy state data and the learning process. Specifically, we will discuss the applicability of the proposed method to two typical scenarios for dynamical systems: parameter identification and estimation with an affine structure of the system, and nonlinear parametric approximation without prior knowledge.},
	urldate = {2024-02-29},
	publisher = {arXiv},
	author = {Ye, Dongwei and Guo, Mengwu},
	month = dec,
	year = {2023},
	note = {arXiv:2312.12193 [cs, math]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computational Engineering, Finance, and Science, Mathematics - Numerical Analysis},
}

@Inbook{Skilling1992,
author="Skilling, John",
editor="Smith, C. Ray
and Erickson, Gary J.
and Neudorfer, Paul O.",
title="Bayesian Solution of Ordinary Differential Equations",
bookTitle="Maximum Entropy and Bayesian Methods: Seattle, 1991",
year="1992",
publisher="Springer Netherlands",
address="Dordrecht",
pages="23--37",
isbn="978-94-017-2219-3",
doi="10.1007/978-94-017-2219-3_2",
url="https://doi.org/10.1007/978-94-017-2219-3_2"
}
@article{roy_comprehensive_2011,
	title = {A comprehensive framework for verification, validation, and uncertainty quantification in scientific computing},
	volume = {200},
	issn = {00457825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782511001290},
	doi = {10.1016/j.cma.2011.03.016},
	language = {en},
	number = {25-28},
	urldate = {2024-03-22},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Roy, Christopher J. and Oberkampf, William L.},
	month = jun,
	year = {2011},
	pages = {2131--2144},
}

@InProceedings{pmlr-v5-alvarez09a,
  title = 	 {Latent Force Models},
  author = 	 {Álvarez, Mauricio and Luengo, David and Lawrence, Neil D.},
  booktitle = 	 {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {9--16},
  year = 	 {2009},
  volume = 	 {5},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v5/alvarez09a/alvarez09a.pdf},
  url = 	 {https://proceedings.mlr.press/v5/alvarez09a.html},
  abstract = 	 {Purely data driven approaches for machine learning present difficulties when data is scarce relative to the complexity of the model or when the model is forced to extrapolate. On the other hand, purely mechanistic approaches  need to identify and specify all the interactions in the problem at hand (which  may not be feasible) and still leave the issue of how to parameterize the system. In this paper, we present a hybrid approach using Gaussian processes and differential equations to combine data driven modeling with a physical model of the system. We show how different, physically-inspired, kernel functions  can be developed through sensible, simple, mechanistic assumptions about the underlying system. The versatility of our approach is illustrated with three case studies from computational biology, motion capture and geostatistics.}
}

@article{bhouri_gaussian_2022,
	title = {Gaussian processes meet {NeuralODEs}: a {Bayesian} framework for learning the dynamics of partially observed systems from scarce and noisy data},
	volume = {380},
	issn = {1364-503X, 1471-2962},
	shorttitle = {Gaussian processes meet {NeuralODEs}},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2021.0201},
	doi = {10.1098/rsta.2021.0201},
	abstract = {We present a machine learning framework (GP-NODE) for Bayesian model discovery from partial, noisy and irregular observations of nonlinear dynamical systems. The proposed method takes advantage of differentiable programming to propagate gradient information through ordinary differential equation solvers and perform Bayesian inference with respect to unknown model parameters using Hamiltonian Monte Carlo sampling and Gaussian Process priors over the observed system states. This allows us to exploit temporal correlations in the observed data, and efficiently infer posterior distributions over plausible models with quantified uncertainty. The use of the Finnish Horseshoe as a sparsity-promoting prior for free model parameters also enables the discovery of parsimonious representations for the latent dynamics. A series of numerical studies is presented to demonstrate the effectiveness of the proposed GP-NODE method including predator–prey systems, systems biology and a 50-dimensional human motion dynamical system.
            This article is part of the theme issue ‘Data-driven prediction in dynamical systems’.},
	language = {en},
	number = {2229},
	urldate = {2024-05-17},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Bhouri, Mohamed Aziz and Perdikaris, Paris},
	month = aug,
	year = {2022},
	pages = {20210201},
}